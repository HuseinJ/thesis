\chapter{Implementation}\label{chapter:implementation}
This chapter documents the empirical investigation of LLM-assisted bounded context extraction, conducted through a systematic comparison of AI-generated domain models against manually-crafted architectures within FTAPI's software ecosystem.

\section{LLM Configuration and Setup}

\subsection{Model Selection and Configuration}
The initial phase focused on evaluating different LLM options for domain modeling tasks. Given the computational resource constraints typical in academic research environments, deploying and running effective open-source models locally proved impractical. Consequently, the evaluation was conducted using commercially available AI chat interfaces, which provided access to state-of-the-art models without requiring extensive computational infrastructure.

\subsubsection{Initial Model Evaluation}
Three leading LLM platforms were selected for preliminary testing based on their documented capabilities in code analysis and architectural reasoning tasks: Claude Opus 4.1 (Anthropic), GPT-5 (OpenAI), and Gemini 2.5 Pro (Google). This selection represented the current state-of-the-art in commercially available large language models, each offering distinct approaches to natural language understanding and reasoning.

\subsubsection{Resource Constraints and Practical Considerations}
The decision to utilize commercial chat interfaces rather than self-hosted open-source alternatives was driven by practical limitations. While open-source models such as LLaMA 2 and CodeLlama were initially considered, the computational requirements for running these models effectively exceeded available hardware resources. The commercial platforms provided consistent access to powerful models without the overhead of infrastructure management, enabling focus on the core research questions rather than technical deployment challenges.

\subsection{Prompt Dependency and Model-Specific Optimization}
It is important to note that the performance differences observed across models likely exhibit strong dependency on the specific prompt engineering approach employed. The varying performance characteristics of each model may be attributed not only to their inherent architectural capabilities but also to the interaction between each model's training characteristics and the particular prompt formulations developed for this research. Different prompt strategies might yield varying relative performance across the evaluated models, suggesting that optimal model selection in LLM-assisted domain modeling requires careful consideration of both model capabilities and prompt engineering compatibility.

Given the uncertainty regarding which model would perform best for the specific task of bounded context identification, all evaluated LLMs were considered and tested throughout the experimental phase. This comprehensive approach allowed for empirical comparison of each model's strengths and weaknesses within the context of domain modeling tasks. The decision to evaluate multiple models rather than committing to a single LLM early in the research process enabled a more robust understanding of how different models interpret and respond to domain modeling prompts.

This multi-model evaluation strategy proved valuable in identifying model-specific behaviors and capabilities that would not have been apparent from theoretical analysis alone. By maintaining flexibility in model selection throughout the experiments, the research could adapt to empirical findings rather than being constrained by initial assumptions about model suitability for DDD-based architectural analysis.

\section{Prompt Engineering Framework}

\subsection{Prompt Development Strategy}
The prompt engineering approach was designed to simulate the experience of working with a senior Domain-Driven Design specialist in an enterprise environment. Rather than simply requesting architectural outputs, the prompts were structured to create an interactive, questioning-based methodology that mirrors real-world DDD consulting practices. This approach aimed to leverage the LLM's reasoning capabilities by embedding it within a realistic professional context where architectural decisions must be justified and explored thoroughly.

\subsection{Role-Based Prompt Architecture}
The prompt engineering strategy centers on establishing a comprehensive role-based framework that positions the LLM as a senior Domain-Driven Design specialist with extensive enterprise experience. This approach moves beyond simple instruction-based prompting to create a professional persona that embodies both expertise and critical thinking capabilities essential for architectural analysis.

\subsubsection{Core Role Definition}
The primary role prompt (see Appendix~\ref{app:role-prompt}) establishes the LLM as a "Senior Domain-Driven Design Specialist \& Architectural Sparring Partner" with over 10 years of enterprise DDD implementation experience. This detailed persona specification serves multiple strategic purposes: it provides contextual grounding for the expected level of architectural sophistication, establishes an interactive rather than passive analytical approach, and creates behavioral expectations for rigorous questioning and assumption challenging.

\subsubsection{Behavioral Guidelines}
The role definition includes specific behavioral instructions that guide the LLM toward DDD best practices enforcement, collaborative modeling approaches, and active challenging of vague or ambiguous concepts. This behavioral framework ensures consistency in how the model approaches domain modeling tasks across different requirement sets.

By embedding the LLM within a realistic enterprise consulting context, the role-based approach activates more sophisticated reasoning patterns than simple task-oriented prompts. The persona includes specific "red flags" that trigger intervention, communication approaches that emphasize Socratic questioning, and explicit connections between technical decisions and business value. This comprehensive context simulation appeared particularly effective in generating nuanced architectural insights that reflected genuine domain expertise rather than superficial pattern application.

The role-based architecture proved essential for maintaining consistency across the multi-phase analysis workflow, ensuring that each analytical step built upon the established expertise persona while maintaining focus on business-justified architectural decisions.

\subsection{Structured Analysis Workflow}

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[
        node distance=0.8cm,
        phase/.style={
            rectangle, rounded corners=4pt, minimum width=7.2cm,
            minimum height=1.4cm, text centered, draw=black, font=\small\bfseries, text width=7cm
        },
        note/.style={font=\scriptsize\itshape},
        arrow/.style={thick,->,>=stealth, color=blue!70},
        feedback/.style={thick,->,>=stealth, dashed, color=gray!60}
    ]
    
    % Title
    \node[font=\Large\bfseries] at (0, 1.2) {LLM-Assisted DDD Analysis Workflow};
    
    % Phases
    \node (phase1) [phase, fill=blue!10] at (0, 0) {
        Phase 1: Ubiquitous Language Establishment\\
        \scriptsize Extract domain vocabulary, define glossary
    };
    
    \node (phase2) [phase, below=of phase1, fill=red!10] {
        Phase 2: Event Storming Simulation\\
        \scriptsize Identify events, commands, actors
    };
    
    \node (phase3) [phase, below=of phase2, fill=orange!10] {
        Phase 3: Bounded Context Identification\\
        \scriptsize Group concepts into cohesive contexts
    };
    
    \node (phase4) [phase, below=of phase3, fill=purple!10] {
        Phase 4: Aggregate Design\\
        \scriptsize Define aggregates, entities, invariants
    };
    
    \node (phase5) [phase, below=of phase4, fill=green!10] {
        Phase 5: Technical Architecture Mapping\\
        \scriptsize Design ports, adapters, infrastructure
    };
    
    \node (output) [phase, below=of phase5, fill=gray!10, minimum height=1.5cm, font=\bfseries] {
        Complete Domain Model\\
        \scriptsize Bounded Contexts • Aggregates • Architecture
    };
    
    % Arrows between phases
    \draw [arrow] (phase1.south) -- (phase2.north);
    \draw [arrow] (phase2.south) -- (phase3.north);
    \draw [arrow] (phase3.south) -- (phase4.north);
    \draw [arrow] (phase4.south) -- (phase5.north);
    \draw [arrow] (phase5.south) -- (output.north);
    
    % Side Labels Aligned to Full Diagram Height
\node[rotate=0, anchor=center, font=\scriptsize, gray] at (-6.5, 0.0) {Requirements Input};

% Dashed Input Arrow pointing to Phase 1
\draw[->, thick, dashed, gray!70] (-5.0, 0.0) -- (phase1.west);
    
    \end{tikzpicture}
    \caption{Refined Five-Phase LLM-Assisted DDD Analysis Workflow}
    \label{fig:refined-ddd-workflow}
    \end{figure}

The prompt framework implements a five-phase analysis workflow, each designed to build upon previous insights while maintaining focus on specific Domain-Driven Design (DDD) aspects. As illustrated in Figure~\ref{fig:refined-ddd-workflow}, this process follows a structured progression from vocabulary definition to technical architecture mapping, culminating in a complete domain model that reflects both business requirements and architectural clarity.

\subsubsection{Phase 1: Ubiquitous Language Establishment}
The initial phase systematically extracts and defines the core domain vocabulary from requirement specifications through a structured glossary approach (see Appendix~\ref{app:ubiquitous-language-prompt}). This foundational step ensures all subsequent analysis operates within a consistent linguistic framework, identifying key business terms, their definitions, contextual usage, and potential ambiguities. The prompt guides the LLM through comprehensive analysis of nouns, verbs, and business concepts while emphasizing business-focused rather than technical definitions. The structured table format captures term definitions, business context, related concepts, and clarification needs, establishing the vocabulary foundation for all architectural decisions.

\subsubsection{Phase 2: Event Storming Simulation}
Building directly upon the established vocabulary, this phase identifies the temporal flow and dynamic behaviors within the system (see Appendix~\ref{app:event-storming-prompt}). The prompt guides the LLM through systematic identification of domain events in chronological order, mapping each event to its triggering commands, responsible actors, applicable policies, and handling aggregates. This phase transforms static vocabulary into dynamic process understanding, revealing the business workflows and state transitions that drive architectural requirements.

\subsubsection{Phase 3: Bounded Context Identification}
The bounded context mapping phase leverages the established vocabulary and process understanding to identify natural boundaries within the domain (see Appendix~\ref{app:bounded-context-prompt}). The prompt directs the LLM to group related terms from the glossary into cohesive contexts, defining each context's core purpose, key aggregates, and context-specific language variations. This phase establishes the high-level architectural boundaries that will guide detailed design decisions.

\subsubsection{Phase 4: Aggregate Design}
Within each identified bounded context, this phase focuses on detailed structural design ensuring proper encapsulation and consistency management (see Appendix~\ref{app:aggregate-design-prompt}). The prompt guides the LLM through identification of aggregate roots, definition of consistency boundaries, specification of contained entities and value objects, and articulation of business invariants. This phase translates conceptual boundaries into concrete structural components.

\subsubsection{Phase 5: Technical Architecture Mapping}
The technical architecture phase translates domain insights into implementable architectural patterns following hexagonal architecture principles (see Appendix~\ref{app:technical-architecture-prompt}). This phase ensures clean separation between domain logic and technical infrastructure while maintaining traceability to business requirements.

\subsubsection{Workflow Integration and Dependencies}
Each phase explicitly builds upon the outputs of the previous ones, creating a cohesive analytical progression from vocabulary definition to detailed implementation guidance. Importantly, each phase is approached as an iterative dialogue with the LLM, allowing for continuous refinement through interactive questioning and clarification until a satisfactory result is achieved. This structured yet flexible process helps prevent common issues such as premature technical decisions or incomplete domain understanding, while ensuring thorough coverage of all relevant DDD architectural concerns.

\section{Requirements Gathering and Preparation}

\subsection{Source Documentation Analysis}
Requirements for both SecuRooms and SecuMails domains were systematically extracted from FTAPI's existing product documentation. This approach ensured that the LLM analysis would be based on the same foundational information used in the development processes.

\subsection{Requirements Compilation Strategy}
SecuRooms represents a smaller domain compared to SecuMails, but provides an ideal validation case since it has already been successfully modularized using manual DDD practices. This existing architecture serves as the benchmark against which LLM-generated models can be evaluated. The SecuMails domain requirements represent the primary target for architectural modernization, encompassing the core email functionality that remains in monolithic form.

\subsection{Input Preparation Strategy}
For both domains, all gathered requirements were consolidated into structured text documents optimized for LLM processing. Requirements were formatted as plain text documents, with each domain's requirements organized in a single file ready for direct input into the AI system. This approach enabled seamless progression through the five-phase analysis workflow while allowing the LLM to maintain context across all phases and build progressively more detailed architectural insights

\section{Architecture Generation Process}
\subsection{LLM-Assisted Domain Model Creation}
Using the prepared requirements documents, both SecuRooms and SecuMails domains were systematically processed through the established five-phase workflow. The analysis generated comprehensive architectural candidates for each domain, with multiple iterations performed where necessary to refine and clarify the resulting domain models.

\subsection{Architecture Candidate Documentation}
The LLM-generated outputs from each phase were systematically captured and consolidated into structured architectural candidates. These candidates included complete bounded context definitions, aggregate specifications, entity relationships, and technical architecture mappings. For SecuRooms, this process produced architectural proposals that could be directly compared against the existing manually-designed implementation.

\subsection{Output Validation and Refinement}
Each generated architecture candidate underwent internal validation to ensure completeness and internal consistency. Where ambiguities or gaps were identified in the initial outputs, additional iterations through relevant workflow phases were conducted to achieve satisfactory architectural coverage.

\section{Expert Evaluation Preparation}

\subsection{Interview Design and Structure}
The expert evaluation was designed around the core research questions. The interview structure incorporated qualitative feedback to capture comprehensive insights.

Given that SecuRooms already has a manually-designed DDD implementation, the interviews were structured to evaluate both domains differently. For SecuRooms, experts could directly compare LLM outputs against the existing proven architecture. For SecuMails, experts assessed the LLM proposals on their own merits as potential modernization strategies.

\subsubsection{Interview Phases and Core Questions}
\label{sec:interview_phases}

The interview was structured into four parts and the following questions were prepared for the interview to guide throughout

\paragraph{Part 1: Introduction and Goal Alignment (5 minutes)}
The objective of this phase was to brief the expert on the purpose of the study.
\begin{itemize}
    \item \textbf{Introduction:} A brief overview of the thesis goal: to evaluate the effectiveness of LLMs in identifying bounded contexts from complex enterprise requirements.
    \item \textbf{Context:} Explanation of the two cases: SecuRooms as a validation case against a known benchmark, and SecuMails as an exploratory case for a monolithic modernization challenge.
    \item \textbf{Task:} Clarification that the expert's role is to critique the AI-generated models based on their deep domain knowledge and experience with Domain-Driven Design.
\end{itemize}

\paragraph{Part 2: Comparative Evaluation of SecuRooms (20 minutes)}
This part focused on directly comparing the LLM-generated model against the existing, human-designed architecture for SecuRooms.

\begin{itemize}
    \item \textbf{Qualitative Probing Questions:}
    \begin{itemize}
        \item "Does the extracted Ubiquitous language represent the real language used for securooms"
        \item "Do the extracted events represent all the events what in the Securooms domain happen? Do you mis anything here ?"
        \item "Did the LLM identify any alternative groupings or potential improvements that we missed during the manual design? Conversely, what critical elements did it completely omit?"
        \item "Do you think the extracted Aggregates represent the real core aggregates we currently have?"
    \end{itemize}
\end{itemize}

\paragraph{Phase 3: Standalone Evaluation of SecuMails (20 minutes)}
This part was conceptualized to assess the LLM-generated architecture for SecuMails on its own merits as a viable modernization strategy.

\begin{itemize}
    \item \textbf{Qualitative Probing Questions:}
    \begin{itemize}
        \item "Based on your understanding of the SecuMails monolithic challenges, does this AI-proposed architecture represent a plausible and effective path forward? Why or why not?"
        \item "If you were tasked with modernizing SecuMails, would you consider this LLM output a useful starting point? What would you change, and what would you keep?"
        \item "Would this proposal be helpful to you as the architect who is tasked with defining a modernized architecture"
    \end{itemize}
\end{itemize}

\paragraph{Phase 4: Overall Impressions and Conclusion (10 minutes)}
This final part should capture the experts' holistic views on the practical implications of this technology.

\begin{itemize}
    \item \textbf{Discussion Questions:}
    \begin{itemize}
        \item "Overall, how would you describe the utility of the LLM as an 'architectural sparring partner' in the domain modeling process?"
        \item "To what extent could this approach accelerate or improve the quality of architectural design at FTAPI, especially considering constraints like tight deadlines and business pressure?"
        \item "What are the most significant limitations or risks you foresee in relying on LLMs for these critical design tasks?"
        \item "Do you have any final recommendations for how this methodology could be improved or applied in the future?"
    \end{itemize}
\end{itemize}

\subsection{Expert Evaluation Execution}
Following the prepared design, a series of semi-structured interviews were conducted with 3 experts from FTAPI Software GmbH. The participants included one tech lead and two senior Developers, each with extensive experience in the company's domain and the principles of Domain-Driven Design. The interviews were conducted via video conference, lasted approximately 50min each, and were recorded and transcribed for analysis. The gathered qualitative data was then thematically analyzed to identify recurring patterns, points of consensus, and divergent opinions regarding the LLM-generated architectural models.